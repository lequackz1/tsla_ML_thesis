# -*- coding: utf-8 -*-
"""$TSLA Reinforcement Learning Stocks v2.4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/lequackz1/54735c69d6a3712b511b4d46928381a5/-tsla-reinforcement-learning-stocks-v2-4.ipynb

## **0. Instalar dependencias e importar librerias**
"""

#Instalar dependencias
!pip install tensorflow-gpu==1.15.0 tensorflow==1.15.0 stable-baselines gym-anytrading gym
!pip install quantstats

#Importar librerias
import gym
import gym_anytrading
import quantstats as qs
import os

from stable_baselines.common.vec_env import DummyVecEnv
from stable_baselines import A2C

import datetime

import numpy as np 
import pandas as pd
import pandas_datareader.data as web
import matplotlib.pyplot as plt

"""## **1. Cargar datos de la acción**

"""

#Definir fecha de inicio y final para obtener datos sobre el ticker del activo
import pandas_datareader.data as web
import datetime

start = datetime.datetime(2015,1,1)
end = datetime.datetime(2021,4,30)

ticker='TSLA'
df = web.DataReader(ticker, 'yahoo', start, end)

#Mostrar la tabla de datos
df.head()

#Cantidad de filas
len(df)

#Borra la columna Adj Close
df.drop(columns="Adj Close")

#Ordena la tabla con el estandar ohlcv
df = df[["Open", "High", "Low","Close","Volume"]]

df.head()

#Imprime los tipos de cada columna
df.dtypes

"""##**2. Agregar indicadores técnicos**

**2.1 Instalar e importar nuevas dependencias**
"""

!pip install finta

#Importa nuevas librerias e indicadores técnicos
from gym_anytrading.envs import StocksEnv
from finta import TA

"""**2.2 Calcular SMA, RSI y OBV**"""

#Crear los indicadores técnicos

df['SMA_12'] = TA.SMA(df, 12)
df['EMA_20'] = TA.EMA(df, 20)
df['EMA_50'] = TA.EMA(df, 50)
df['EMA_100'] = TA.EMA(df, 100)
df['EMA_200'] = TA.EMA(df, 200)
df['RSI'] = TA.RSI(df)
df['STOCH'] = TA.STOCH(df) 
df.fillna(0, inplace=True) #Reemplaza los valores nulos con 0

#Mostrar los indicadores técnicos agregados a la tabla df
df.head(100)

"""


**2.3 Crear nuevo entornos**"""

#Agregar los indicadores técnicos al aprendizaje del agente
def add_signals(env):
  start = env.frame_bound[0] - env.window_size
  end = env.frame_bound[1]
  prices = env.df.loc[:, 'Low'].to_numpy()[start:end]
  signal_features = env.df.loc[:, ['Low', 'Volume', 'SMA_12', 'EMA_20', 'EMA_50','EMA_100', 'EMA_200','RSI', 'STOCH']].to_numpy()[start:end]
  return prices, signal_features

#Define el nuevo entorno con los indicadores técnicos incorporados
frame_start=250
frame_end=1258

class MyCustomEnv(StocksEnv):
  _process_data = add_signals
  
env2 = MyCustomEnv(df=df, window_size=12, frame_bound=(frame_start,frame_end))

#Señales disponibles, diferencia de precios intradia e indicadores
env2.signal_features

#Acciones posibles del agente, posición larga (1) o corta (0)
env2.action_space

"""## **3. Construir entorno y entrenar**

**3.1 Entrenar y guardar modelos**
"""

l = []
for i in range(1, 11):
  env_maker = lambda:env2
  env = DummyVecEnv([env_maker])
  model = A2C('MlpLstmPolicy', env, verbose=1)
  model.learn(total_timesteps=100000)
  env2._calculate_reward
  env2._process_data
  env = MyCustomEnv(df=df, window_size=12, frame_bound=(frame_start, frame_end))
  obs = env.reset()
  while True:
    obs = obs[np.newaxis, ...]
    action, _states = model.predict(obs)
    obs, rewards, done, info = env.step(action)
    if done:
      model.save('A2C_Modelo_TSLA'+str(i))
      l.append({'model':'A2C_Modelo_TSLA'+str(i),'info':info})
      del model
      break
print(l)

"""## **4. Cargar y evaluar modelo**


"""

#Cargar modelo seleccionado
env_maker = lambda:env2
env = DummyVecEnv([env_maker])
model = A2C.load('A2C_v2_Modelo_TSLA1', env=env)

#Función que borra el modelo cargado
#del model

#Testear modelo
test_frame_start= 1256
test_frame_end= 1511

l = []
for i in range(1, 101):
  env = MyCustomEnv(df=df, window_size=12, frame_bound=(test_frame_start, test_frame_end))
  obs = env.reset()
  while True:
    obs = obs[np.newaxis, ...]
    action, _states = model.predict(obs)
    obs, rewards, done, info = env.step(action)
    if done:
      print("n="+str(i))
      print("info", info)
      plt.figure(figsize=(15,6))
      env.render_all()
      plt.show()
      qs.extend_pandas()
      net_worth = pd.Series(env.history['total_profit'], index=df.index[test_frame_start+1:test_frame_end])
      returns = net_worth.pct_change().iloc[1:]
      qs.reports.basic(returns)
      break
print(l)

#Rendimiento del agente
qs.extend_pandas()

net_worth = pd.Series(env.history['total_profit'], index=df.index[test_frame_start+1:test_frame_end])
returns = net_worth.pct_change().iloc[1:]

qs.reports.basic(returns)